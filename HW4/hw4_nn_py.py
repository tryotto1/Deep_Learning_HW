# -*- coding: utf-8 -*-
"""hw4_nn.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cygDcZJta2ttKqNIG98KCJjty6D5yXNb
"""

import numpy as np
from skimage.util.shape import view_as_windows

import numpy as np
from skimage.util.shape import view_as_windows


##########
#   convolutional layer
#   you can re-use your previous implementation, or modify it if necessary
##########

class nn_convolutional_layer:

    def __init__(self, Wx_size, Wy_size, input_size, in_ch_size, out_ch_size, std=1e0):

        # initialization of weights
        self.W = np.random.normal(0, std / np.sqrt(in_ch_size * Wx_size * Wy_size / 2),
                                  (out_ch_size, in_ch_size, Wx_size, Wy_size))
        self.b = 0.01 + np.zeros((1, out_ch_size, 1, 1))
        self.input_size = input_size

    def update_weights(self, dW, db):
        self.W += dW
        self.b += db

    def get_weights(self):
        return self.W, self.b

    def set_weights(self, W, b):
        self.W = W
        self.b = b

    def forward(self, x):
        batch_size = x.shape[0]
        filter_size = self.W.shape[0]
        filter_width = self.W.shape[2]
        output_size = x.shape[2] - self.W.shape[2] + 1

        # 최종 output shape
        active = np.zeros((batch_size, filter_size, output_size, output_size))

        for idx_batch in range(x.shape[0]):
            for idx_filter in range(self.W.shape[0]):
                # fileter = (3,3,3), bias=(1,1)
                filter = self.W[idx_filter]
                bias = self.b[0][idx_filter]

                out_rgb_sum = np.zeros((output_size, output_size))
                for idx_rgb in range(x.shape[1]):
                    ''' x 설정 '''
                    # rgb_x = (32,32)
                    # rgb_x_window = (30,30,3,3)->(30,30,9)
                    rgb_x = x[idx_batch][idx_rgb]
                    rgb_x_window = view_as_windows(rgb_x, (filter_width, filter_width)).reshape(
                        (output_size, output_size, -1))

                    ''' filter 설정 '''
                    # filter_rgb = (3,3) -> (9, )
                    # tmp_rgb = (30,30)
                    filter_rgb = filter[idx_rgb]
                    filter_rgb = filter_rgb.reshape((-1, 1))

                    ''' x, filter 곱 '''
                    out_rgb = rgb_x_window.dot(filter_rgb)
                    out_rgb = np.squeeze(out_rgb, axis=2)

                    ''' output을 rgb에 대해 더해주기 '''
                    out_rgb_sum = out_rgb_sum + out_rgb

                ''' 최종 output active에 쌓아주기'''
                # active = (8,30,30)
                active[idx_batch][idx_filter] = out_rgb_sum + bias

        return active

    def backprop(self, x, dLdy):
        batch_size = x.shape[0]
        filter_size = self.W.shape[0]
        rgb_size = x.shape[1]
        output_size = x.shape[2] - self.W.shape[2] + 1
        input_size = x.shape[2]

        # dLdx=(8,3,32,32), dLdW=(8,3,3,3), dLdb=(1,8,1,1)
        dLdx = np.zeros((batch_size, rgb_size, input_size, input_size))
        dLdW = np.zeros((filter_size, rgb_size, self.W.shape[2], self.W.shape[3]))
        dLdb = np.zeros((1, filter_size, 1, 1))

        ''' dLdx '''
        # dLdy shape=(8,8,30,30), W =(8,3,3,3), b shape=(1,8,1,1), x shape=(8,3,32,32)
        for idx_batch in range(dLdy.shape[0]):
            for idx_filter in range(dLdy.shape[1]):
                # filter = (3,3,3)
                filter = self.W[idx_filter]

                for idx_rgb in range(x.shape[1]):
                    # part_filter = (3,3)
                    part_filter = filter[idx_rgb]
                    part_filter = np.rot90(np.rot90(part_filter))

                    # part_dldy=(30,30), pad_dldy=(34,34)
                    part_dldy = dLdy[idx_batch][idx_filter]
                    pad_dldy = np.pad(array=part_dldy, pad_width=2)

                    # window_part_dldy = (32,32,3,3) -> window_part_dldy=(32,32,9)
                    # part_filter=(9, ), dot_product=(32,32)
                    window_part_dldy = view_as_windows(pad_dldy, (self.W.shape[2], self.W.shape[3])).reshape(
                        (input_size, input_size, -1))
                    dot_product = window_part_dldy.dot(part_filter.reshape(-1, 1)).squeeze()

                    # dLdx update
                    dLdx[idx_batch][idx_rgb] = dLdx[idx_batch][idx_rgb] + dot_product

        ''' dLdW '''
        for idx_batch in range(dLdy.shape[0]):
            for idx_filter in range(dLdy.shape[1]):
                # part_dldy=(30,30)
                part_dldy = dLdy[idx_batch][idx_filter]

                for idx_rgb in range(x.shape[1]):
                    # part_x=(32,32)
                    # window_part_dldy=(3,3,900), dot_product=(3,3)
                    part_x = x[idx_batch][idx_rgb]
                    window_part_x = view_as_windows(part_x, (output_size, output_size)).reshape(
                        (self.W.shape[2], self.W.shape[3], -1))
                    dot_product = window_part_x.dot(part_dldy.reshape((-1, 1))).squeeze()

                    dLdW[idx_filter][idx_rgb] = dLdW[idx_filter][idx_rgb] + dot_product

        ''' dLdb '''
        for idx_batch in range(dLdy.shape[0]):
            for idx_filter in range(dLdy.shape[1]):
                part_dldy = dLdy[idx_batch][idx_filter]
                dot_product = part_dldy.reshape(-1, 1).sum()

                dLdb[0][idx_filter][0][0] = dLdb[0][idx_filter][0][0] + dot_product

        return dLdx, dLdW, dLdb

##########
#   max pooling layer
#   you can re-use your previous implementation, or modify it if necessary
##########

class nn_max_pooling_layer:
    def __init__(self, stride, pool_size):
        self.stride = stride
        self.pool_size = pool_size

    def forward(self, x):
        batch_size = x.shape[0]
        rgb_size = x.shape[1]
        input_size = x.shape[2]

        # 미리 행렬 설정
        self.back_idx = np.zeros((batch_size, rgb_size, input_size, input_size))
        rst_maxpool = np.zeros((batch_size, rgb_size, input_size // 2, input_size // 2))

        # x=(8,3,32,32)
        for idx_batch in range(x.shape[0]):
            for idx_rgb in range(x.shape[1]):
                # part_x=(32,32)
                # window_part_x=(16,16,2,2) -> (16,16,4)
                part_x = x[idx_batch][idx_rgb]
                window_part_x = view_as_windows(part_x, self.pool_size, self.stride).reshape(
                    (input_size // 2, input_size // 2, -1))

                for row in range(window_part_x.shape[0]):
                    for col in range(window_part_x.shape[1]):
                        rst_maxpool[idx_batch][idx_rgb][row][col] = np.max(window_part_x[row][col])

                        idx = np.argmax(window_part_x[row][col])
                        plus_row = idx // 2
                        plus_col = idx % 2

                        self.back_idx[idx_batch][idx_rgb][2 * row + plus_row][2 * col + plus_col] = 1

        return rst_maxpool

    def backprop(self, x, dLdy):
        batch_size = x.shape[0]
        rgb_size = x.shape[1]
        input_size = x.shape[2]

        # 미리 행렬 설정
        dLdx = np.zeros((batch_size, rgb_size, input_size, input_size))

        # dLdy=(2,28,13,13), x=(2,28,26,26)
        dLdy = dLdy.reshape((x.shape[0],x.shape[1],x.shape[2]//2,x.shape[3]//2))
        for idx_batch in range(x.shape[0]):
            for idx_rgb in range(x.shape[1]):
                part_dldy = dLdy[idx_batch][idx_rgb]

                for row in range(x.shape[2]):
                    for col in range(x.shape[3]):
                        dLdx[idx_batch][idx_rgb][row][col] = self.back_idx[idx_batch][idx_rgb][row][col] * part_dldy[row // 2][col // 2]

        return dLdx

# testing the implementation

# data sizes
batch_size = 8
input_size = 32
filter_width = 3
filter_height = filter_width
in_ch_size = 3
num_filters = 8

std = 1e0
dt = 1e-3

# number of test loops
num_test = 20

# error parameters
err_dLdb = 0
err_dLdx = 0
err_dLdW = 0
err_dLdx_pool = 0

for i in range(num_test):
    # create convolutional layer object
    cnv = nn_convolutional_layer(filter_width, filter_height, input_size, in_ch_size, num_filters, std)

    x = np.random.normal(0, 1, (batch_size, in_ch_size, input_size, input_size))
    delta = np.random.normal(0, 1, (batch_size, in_ch_size, input_size, input_size)) * dt

    # dLdx test
    print('dLdx test')
    y1 = cnv.forward(x)
    y2 = cnv.forward(x + delta)
    
    bp, _, _ = cnv.backprop(x, np.ones(y1.shape))

    exact_dx = np.sum(y2 - y1) / dt
    apprx_dx = np.sum(delta * bp) / dt
    print('exact change', exact_dx)
    print('apprx change', apprx_dx)

    err_dLdx += abs((apprx_dx - exact_dx) / exact_dx) / num_test * 100

    # dLdW test
    print('dLdW test')
    W, b = cnv.get_weights()
    dW = np.random.normal(0, 1, W.shape) * dt
    db = np.zeros(b.shape)

    z1 = cnv.forward(x)
    _, bpw, _ = cnv.backprop(x, np.ones(z1.shape))
    cnv.update_weights(dW, db)
    z2 = cnv.forward(x)

    exact_dW = np.sum(z2 - z1) / dt
    apprx_dW = np.sum(dW * bpw) / dt
    print('exact change', exact_dW)
    print('apprx change', apprx_dW)

    err_dLdW += abs((apprx_dW - exact_dW) / exact_dW) / num_test * 100

    # dLdb test
    print('dLdb test')

    W, b = cnv.get_weights()

    dW = np.zeros(W.shape)
    db = np.random.normal(0, 1, b.shape) * dt

    z1 = cnv.forward(x)

    V = np.random.normal(0, 1, z1.shape)

    _, _, bpb = cnv.backprop(x, V)

    cnv.update_weights(dW, db)
    z2 = cnv.forward(x)

    exact_db = np.sum(V * (z2 - z1) / dt)
    apprx_db = np.sum(db * bpb) / dt

    print('exact change', exact_db)
    print('apprx change', apprx_db)
    err_dLdb += abs((apprx_db - exact_db) / exact_db) / num_test * 100

    # max pooling test
    # parameters for max pooling
    stride = 2
    pool_size = 2

    mpl = nn_max_pooling_layer(stride=stride, pool_size=pool_size)

    x = np.arange(batch_size * in_ch_size * input_size * input_size).reshape(
        (batch_size, in_ch_size, input_size, input_size)) + 1
    delta = np.random.normal(0, 1, (batch_size, in_ch_size, input_size, input_size)) * dt

    print('dLdx test for pooling')
    y1 = mpl.forward(x)
    dLdy = np.random.normal(0, 10, y1.shape)
    bpm = mpl.backprop(x, dLdy)

    y2 = mpl.forward(x + delta)

    exact_dx_pool = np.sum(dLdy * (y2 - y1)) / dt
    apprx_dx_pool = np.sum(delta * bpm) / dt
    print('exact change', exact_dx_pool)
    print('apprx change', apprx_dx_pool)

    err_dLdx_pool += abs((apprx_dx_pool - exact_dx_pool) / exact_dx_pool) / num_test * 100

# reporting accuracy results.
print('accuracy results')
print('conv layer dLdx', 100 - err_dLdx, '%')
print('conv layer dLdW', 100 - err_dLdW, '%')
print('conv layer dLdb', 100 - err_dLdb, '%')
print('maxpool layer dLdx', 100 - err_dLdx_pool, '%')

